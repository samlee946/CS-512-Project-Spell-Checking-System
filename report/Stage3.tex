
We are using Python 3.7 as our programming languange for this project. 
The programming environment is as follows:
\paragraph{Operating System}{Ubuntu 18.04.1 LTS 64-bit}
\paragraph{Processor}{Intel$ ^\text{\textregistered} $ Core$ ^{\text{\texttrademark}} $ i7-8700K CPU}
\paragraph{Memory}{16 GB DDR4-3200 Memory}
\paragraph{Graphics Card}{GTX 1070ti} \\
%Building the corresponding relational tables, according to the proposed ER model described in the previous phase %enforcing the different integrity constraints.  
The deliverables for this stage include the following items:
\begin{itemize} 
\item{}
Sample small data snippet: \\
%The SQL tables that represent the ER project model, along with at least 3-5 rows of concrete data per table.
``Aoccdrnig to a rscheearch at Cmabrigde Uinervtisy, it deosn't mttaer in waht oredr the ltteers in a wrod are, the olny iprmoetnt tihng is taht the frist and lsat ltteer be at the rghit pclae. The rset can be a toatl mses and you can sitll raed it wouthit porbelm. Tihs is bcuseae the huamn mnid deos not raed ervey lteter by istlef, but the wrod as a wlohe.''
\item{}
Sample small output: \\
%The normalization steps for each table, along with explanations/justifications of each normalization step.
\textbf{If we use the program's auto correction:} ``Aoccdrnig to a rscheearch at Cmabrigde Uinervtisy, it doesnt matter in what order the ltteers in a word are, the only iprmoetnt thing is that the frist and last letter be at the right place. the set can be a total mess and you can still read it outhit problem. this is abusee the human mind does not read every letter by istle, but the word as a wolve.'' \\
\textbf{If we choose the best suggestion in the list:} ``Aoccdrnig to a rscheearch at Cmabrigde Uinervtisy, it doesnt matter in what order the ltteers in a word are, the only iprmoetnt thing is that the frist and last letter be at the right place. The rest can be a total mess and you can still read it outhit problem. this is abusee the human mind does not read every letter by itself, but the word as a wolve.''
\item{}

Working code: \\
\textbf{The code of Trie (Ternary Search tree)} \\
\begin{minted}{python}
class Trie:
  root = None
  def __init__(self):
    self.root = None
  def insert(self, word, rank):
    self.root = insert(self.root,
      word, rank)
  def find(self, word):
    return find(self.root, word)

class Node:
  leftChild = None
  rightChild = None
  centerChild = None
  indicator = False
  character = None
  value = 99999
  def __init__(self, character):
    self.character = character

def insert(node, word, rank):
  if len(word) == 0:
    return node
  if node is None:
    node = Node(word[0])
  if word[0] < node.character:
    node.leftChild = insert(
      node.leftChild, word, rank)
  elif word[0] > node.character:
    node.rightChild = insert(
      node.rightChild, word, rank)
  else:
    if len(word[1:]) == 0:
      node.indicator = True
      node.value = int(rank)
    else:
      node.centerChild = insert(
        node.centerChild, 
        word[1:], rank)
  return node

def find(node, word):
  if node is None or len(word) == 0:
    return (False, 99999)
  if word[0] < node.character:
    return find(node.leftChild, word)
  elif word[0] > node.character:
    return find(node.rightChild, word)
  else:
    if len(word) == 1 and 
       node.indicator == True:
      return (True, node.value)
    return find(node.centerChild, 
          word[1:])
\end{minted}
\textbf{The code of the checker:} \\
\begin{minted}{python}
def check_word(trie, word):
  suggest_list = []
  suggest_list_without_rank = []
  print(check_dictionary(trie, word))
  check_result, word_rank = 
    check_dictionary(trie, word)
  if check_result == False:
    edited_word_list = word
    for i in range(3):
      if len(suggest_list) >= 8:
        break
      edited_word_list = edit_word(
        edited_word_list, i + 1)
      for edited_word in 
        edited_word_list:
        if edited_word in
          suggest_list_without_rank:
          continue
        if len(suggest_list) >= 8:
          break
        check_result, word_rank = 
          check_dictionary(trie,
            edited_word)
        if check_result == True:
          suggest_list.append(
            (edited_word, i,
              word_rank))
          suggest_list_without
_rank.append(edited_word)
    suggest_list = sorted(suggest_list,
      key=itemgetter(1, 2))
    if len(suggest_list) == 0:
      suggest_list.append(
        ('No suggestion', 9, 99999))
  return suggest_list

def edit_word(word_or_list, edit_distance):
  if edit_distance <= 1:
    return edit_word_once(word_or_list)
  else:
    edited_list = []
    for edited_word in word_or_list:
      if len(edited_list) > 100000:
        break
      edited_list += edit_word_once(
        edited_word)
    return edited_list

def edit_word_once(word):
  splits = []
  delete_list = []
  traspose_list = []
  replace_list = []
  insert_list = []
  result = []
  for i in range(len(word) + 1):
    splits.append((word[0:i], word[i:]))
  for (a, b) in splits:
    if len(b) >= 1:
      delete_list.append(a + b[1:])
      for c in string.ascii_lowercase:
        replaced_word = a + c + b[1:]
        if word == replaced_word:
          continue
        replace_list.append(
          replaced_word)
    if len(b) >= 2:
      second_half = b[1] + b[0] + b[2:]
      traspose_list.append(a + 
        second_half)
    for c in string.ascii_lowercase:
      insert_list.append(a + c + b)
  result = traspose_list + delete_list +
    replace_list + insert_list
  return result

def check_dictionary(trie, word):
  return trie.find(word)

def load_dictionary_from_json(filepath):
  with open(filepath) as dictionary_file:
    words = set(dictionary_file.read()
.split())
  return words

def load_dictionary_from_txt(filepath):
  with open(filepath) as dictionary_file:
    words = dictionary_file.readlines()
  words = [word.split() 
        for word in words]
  return words

def load_dictionary_to_trie(words, trie):
  for word, rank in words:
    trie.insert(word.strip(), 
      rank.strip())

def check_text(text):
  global trie_basic
  global trie_235k
  suggest_list_of_all_words = []
  for i in range(len(text)):
    suggest_list_of_all_words.append([])
    if text[i] in string.punctuation:
      continue
    print('Finding suggestions ' +
      'with respesct to ' + text[i])
    if text[i] == 'i':
      suggest_list_of_all_words[i]
.append('I')
      continue
    suggest_list_of_all_words[i] = 
      check_word(trie_235k, text[i])
  print(suggest_list_of_all_words)
  return suggest_list_of_all_words
\end{minted}
%The SQL table after the normalization steps (showing all table attributes).
\item{}
Demo and sample findings
%The SQL statements used to create the SQL tables, including the required triggers as well as the integrity constraints. At %least 2 triggers and 2 of each of the following constraint types have to exist in the project tables overall: 
\begin{itemize} 
\item{}
	Data size: We have around 240,000 English vocabularies storing in a txt file of 2.5 MB. After fully loaded, the program takes around 300 MB of memory.
\item{}
	The accuracy of this program heavily depends on the vocabulary we have, and it is hard to do a perfect English spell checking system using merely Trie.
%Whether some users will be denied access and/or updates to some data according to their roles (for example: student1 %can not access other students' ' grades, so a violation error pops up upon that action. Another example: a sales person %can see an item price, but can not change it, since only a manger can, also a violation error pops up upon that update %attempt).
\end{itemize}
\end{itemize}

